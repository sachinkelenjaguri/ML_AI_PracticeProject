{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SPARK_HOME and PYLIB env var and update PATH env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build __SparkConf__ object \n",
    "\n",
    "    Contains information about your application.  \n",
    "\n",
    "\n",
    "Create __SparkContext__ object \n",
    "    \n",
    "    Tells Spark how to access a cluster. \n",
    "    \n",
    "\n",
    "Create __SparkSession__ object\n",
    "\n",
    "    The entry point to programming Spark with the Dataset and DataFrame API.\n",
    "\n",
    "    Used to create DataFrame, register DataFrame as tables and execute SQL over tables etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"Universal Bank Data Set\").setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loading the dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "# from pyspark.sql.functions import isnan, when, count, col, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem Statement\n",
    "The dataset is from a bank, data related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, to access if the product (bank term deposit) would be (or not) subscribed. The data and attribute description are in the folder. \n",
    "\n",
    "\n",
    "#### Data Dictionary\n",
    " The dataset has the following attributes:\n",
    "\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                    \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "\n",
    "3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "\n",
    "5 - default: has credit in default? (binary: \"yes\",\"no\")\n",
    "\n",
    "#### 6 - balance: average yearly balance, in euros (numeric) \n",
    "\n",
    "7 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "\n",
    "10 - day: last contact day of the month (numeric)\n",
    "\n",
    "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "\n",
    "12 - duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "  \n",
    "15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "17 - Approved_no_yes - has the client subscribed to a __term deposit?__ (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the schema to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define Schema\n",
    "bankDataSchema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"default\", StringType(), True),\n",
    "    StructField(\"balance\", DoubleType(), True),\n",
    "    StructField(\"housing\", StringType(), True),\n",
    "    StructField(\"loan\", StringType(), True),        \n",
    "    StructField(\"contact\", StringType(), True),\n",
    "    StructField(\"day\", IntegerType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"duration\", DoubleType(), True),\n",
    "    StructField(\"campaign\", DoubleType(), True),\n",
    "    StructField(\"pdays\", DoubleType(), True),\n",
    "    StructField(\"previous\", DoubleType(), True),\n",
    "    StructField(\"poutcome\", StringType(), True),\n",
    "    StructField(\"Approved_no_yes\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data and creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read data and create a dataframe\n",
    "data = spark.read.format(\"csv\")\\\n",
    "       .option(\"header\", \"false\")\\\n",
    "       .option(\"inferSchema\", \"true\")\\\n",
    "       .load(\"hdfs:///user/jeevans/bankdata/\", schema = bankDataSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- campaign: double (nullable = true)\n",
      " |-- pdays: double (nullable = true)\n",
      " |-- previous: double (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- Approved_no_yes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to check the data type of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital_status', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'double'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'int'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'double'),\n",
       " ('campaign', 'double'),\n",
       " ('pdays', 'double'),\n",
       " ('previous', 'double'),\n",
       " ('poutcome', 'string'),\n",
       " ('Approved_no_yes', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of Columns and Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Columns = 17\n",
      "No. of Records = 4521\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Columns = {}\".format(len(data.columns)))\n",
    "\n",
    "print('No. of Records = {}'.format(data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at first 3 row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=30, job=u'unemployed', marital_status=u'married', education=u'primary', default=u'no', balance=1787.0, housing=u'no', loan=u'no', contact=u'cellular', day=19, month=u'oct', duration=79.0, campaign=1.0, pdays=-1.0, previous=0.0, poutcome=u'unknown', Approved_no_yes=u'no'),\n",
       " Row(age=33, job=u'services', marital_status=u'married', education=u'secondary', default=u'no', balance=4789.0, housing=u'yes', loan=u'yes', contact=u'cellular', day=11, month=u'may', duration=220.0, campaign=1.0, pdays=339.0, previous=4.0, poutcome=u'failure', Approved_no_yes=u'no'),\n",
       " Row(age=35, job=u'management', marital_status=u'single', education=u'tertiary', default=u'no', balance=1350.0, housing=u'yes', loan=u'no', contact=u'cellular', day=16, month=u'apr', duration=185.0, campaign=1.0, pdays=330.0, previous=1.0, poutcome=u'failure', Approved_no_yes=u'no')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|age|       job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "| 30|unemployed|       married|  primary|     no| 1787.0|     no|  no|cellular| 19|  oct|    79.0|     1.0| -1.0|     0.0| unknown|             no|\n",
      "| 33|  services|       married|secondary|     no| 4789.0|    yes| yes|cellular| 11|  may|   220.0|     1.0|339.0|     4.0| failure|             no|\n",
      "| 35|management|        single| tertiary|     no| 1350.0|    yes|  no|cellular| 16|  apr|   185.0|     1.0|330.0|     1.0| failure|             no|\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "|summary|               age|    job|marital_status|education|default|           balance|housing|loan| contact|               day|month|          duration|          campaign|             pdays|          previous|poutcome|Approved_no_yes|\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "|  count|              4521|   4521|          4521|     4521|   4521|              4521|   4521|4521|    4521|              4521| 4521|              4521|              4521|              4521|              4521|    4521|           4521|\n",
      "|   mean| 41.17009511170095|   null|          null|     null|   null|1422.6578190665782|   null|null|    null|15.915284229152842| null|263.96129174961294| 2.793629727936297|39.766644547666445|0.5425790754257908|    null|           null|\n",
      "| stddev|10.576210958711263|   null|          null|     null|   null|3009.6381424673395|   null|null|    null| 8.247667327229934| null|259.85663262468216|3.1098066601885823|100.12112444301656|1.6935623506071211|    null|           null|\n",
      "|    min|                19| admin.|      divorced|  primary|     no|           -3313.0|     no|  no|cellular|                 1|  apr|               4.0|               1.0|              -1.0|               0.0| failure|             no|\n",
      "|    max|                87|unknown|        single|  unknown|    yes|           71188.0|    yes| yes| unknown|                31|  sep|            3025.0|              50.0|             871.0|              25.0| unknown|            yes|\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show only fixed set of colums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----+------------------+------------------+\n",
      "|summary|               age|loan|           balance|             pdays|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "|  count|              4521|4521|              4521|              4521|\n",
      "|   mean| 41.17009511170095|null|1422.6578190665782|39.766644547666445|\n",
      "| stddev|10.576210958711263|null|3009.6381424673395|100.12112444301656|\n",
      "|    min|                19|  no|           -3313.0|              -1.0|\n",
      "|    max|                87| yes|           71188.0|             871.0|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().select('summary', 'age', 'loan', 'balance', 'pdays').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "\n",
    "    Balance has -ve values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.where(data.balance < 0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace negative balances with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.withColumn('balance', when(data.balance > 0, data.balance).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values at each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|age|job|marital_status|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|  0|  0|             0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|              0|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and test sets (30% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list of categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_Var_Names = ['job', 'marital_status', 'education', 'default', 'housing', \n",
    "                 'day', 'contact', 'month', 'poutcome', 'Approved_no_yes']\n",
    "\n",
    "num_Var_Names = ['age', 'balance', 'duration', 'previous', 'pdays', 'campaign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use VectorAssembler to combine a given list of numcolumns into a single vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler_Num = VectorAssembler(inputCols=num_Var_Names, outputCol=\"num_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale all the numeric attributes using MinMaxScaler\n",
    "\n",
    "    MinMaxScaler transforms a dataset of Vector rows, rescaling each feature to a specific range (often [0, 1]). \n",
    "\n",
    "    MinMaxScaler computes summary statistics on a data set and produces a MinMaxScalerModel. The model can then transform each feature individually such that it is in the given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "min_Max_Scalar = MinMaxScaler(inputCol=\"num_features\", outputCol=\"scaled_num_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covert categorical to numeric : \n",
    "\n",
    "    OneHotEncoder, StringIndexer, VectorAssembler,  VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "indexers_Cat = [StringIndexer(inputCol=cat_Var_Name, outputCol=\"{0}_index\".format(cat_Var_Name)) for cat_Var_Name in cat_Var_Names ]\n",
    "encoders_Cat = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_vec\".format(indexer.getInputCol())) for indexer in indexers_Cat]\n",
    "assembler_Cat = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders_Cat], outputCol=\"cat_features\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"scaled_num_features\",\"cat_features\"], outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer_Label = StringIndexer(inputCol=\"loan\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessiong_Stages = [assembler_Num]+[min_Max_Scalar]+indexers_Cat+encoders_Cat+[assembler_Cat]+[assembler]+[indexer_Label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr_Pipeline = Pipeline(stages=preprocessiong_Stages+[lr]) \n",
    "\n",
    "lr_Pipeline_model = lr_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.710121916343,-4.22902246315,0.354450780907,0.96947748232,0.27027464059,0.594143226419,0.125406707623,-0.00525985643844,0.107542040447,0.218256974689,0.11076213061,-0.000603590384907,0.666917451831,-0.094787492947,-0.548774363689,0.129175403917,-1.56240534608,0.124815247247,-0.226883832814,0.40103725583,0.149467438393,-0.0972437476018,-1.14962987804,-0.0544964913157,-0.407736749923,-0.0858331192117,-0.403963999896,0.219865778816,0.387569612049,0.628272118039,0.318435467906,0.305670414001,0.161814851413,-0.181409055233,-0.230825819583,0.241599806793,0.258564743629,0.0947740436397,-0.196137456599,-0.213754811455,0.486203492319,-0.291596052914,-0.67092955477,-0.0418712904755,0.100112210365,0.159000451578,0.15550132615,-0.425501251642,0.0687629051454,-1.25397577177,0.874864751866,0.165986768255,-0.984977941963,-0.228463529061,-0.061212600242,0.13486363404,-0.253825360017,0.970952231844,-0.257997951761,-0.239287136223,0.502444321536,-0.21306340475,-0.0402448583029,-0.395961488803,0.28513237474,-0.788798697646,-1.2620585774,0.305064021023,0.162199774629,0.240801930129,0.628311548322]\n",
      "Intercept: -1.75317326461\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(lr_Pipeline_model.stages[-1].coefficients))\n",
    "print(\"Intercept: \" + str(lr_Pipeline_model.stages[-1].intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.415645100646\n",
      "0.394291354729\n",
      "0.388490505959\n",
      "0.388126580716\n",
      "0.387368409818\n",
      "0.385654601826\n",
      "0.383891342298\n",
      "0.382288921054\n",
      "0.381840536009\n",
      "0.381659163401\n",
      "0.381388955797\n"
     ]
    }
   ],
   "source": [
    "lr_Summary = lr_Pipeline_model.stages[-1].summary\n",
    "objectiveHistory = lr_Summary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_lr = lr_Pipeline_model.transform(trainingData)\n",
    "test_predictions_lr = lr_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|label|       rawPrediction|         probability|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "| 19|student|        single|  primary|     no|  103.0|     no|  no|cellular| 10|  jul|   104.0|     2.0| -1.0|     0.0| unknown|            yes|[19.0,103.0,104.0...|[0.0,0.0014468730...|     10.0|                 1.0|            2.0|          0.0|          1.0|     27.0|          0.0|        1.0|           0.0|                  1.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[2],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[27],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|          (1,[],[])|(65,[10,12,15,16,...|(71,[1,2,5,16,18,...|  0.0|[3.39080623924584...|[0.96741596879805...|       0.0|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no|cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|             no|[19.0,0.0,123.0,0...|[0.0,0.0,0.039390...|     10.0|                 1.0|            3.0|          0.0|          1.0|     17.0|          0.0|        6.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|    (3,[],[])|(1,[0],[1.0])|  (1,[],[])|(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(65,[10,12,16,35,...|(71,[2,5,16,18,22...|  0.0|[4.11355737376797...|[0.98391349680298...|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_lr.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.855611601513\n",
      "Test accuracy = 0.833209785026\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "predictionAndLabels_train_lr = train_predictions_lr.select(\"prediction\", \"label\")\n",
    "train_accuracy_lr = evaluator.evaluate(predictionAndLabels_train_lr)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_lr))\n",
    "\n",
    "predictionAndLabels_test_lr = test_predictions_lr.select(\"prediction\", \"label\")\n",
    "test_accuracy_lr = evaluator.evaluate(predictionAndLabels_test_lr)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.5])\\\n",
    "    .build()\n",
    "    \n",
    "lr_crossval = CrossValidator(estimator=lr_Pipeline,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "lr_crossval_Model = lr_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_lrcv = lr_crossval_Model.transform(trainingData)\n",
    "test_predictions_lrcv = lr_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.854035308953\n",
      "Test set accuracy = 0.830985915493\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_lrcv = train_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "train_accuracycv = evaluator.evaluate(predictionAndLabels_train_lrcv)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracycv))\n",
    "\n",
    "predictionAndLabels_test_lrcv = test_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "test_accuracycv = evaluator.evaluate(predictionAndLabels_test_lrcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracycv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_Pipeline = Pipeline(stages=preprocessiong_Stages+[dt]) \n",
    "\n",
    "dt_Pipeline_model = dt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_dt = dt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_dt = dt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+-------------+--------------------+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|label|rawPrediction|         probability|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+-------------+--------------------+----------+\n",
      "| 19|student|        single|  primary|     no|  103.0|     no|  no|cellular| 10|  jul|   104.0|     2.0| -1.0|     0.0| unknown|            yes|[19.0,103.0,104.0...|[0.0,0.0014468730...|     10.0|                 1.0|            2.0|          0.0|          1.0|     27.0|          0.0|        1.0|           0.0|                  1.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[2],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[27],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|          (1,[],[])|(65,[10,12,15,16,...|(71,[1,2,5,16,18,...|  0.0| [127.0,81.0]|[0.61057692307692...|       0.0|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no|cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|             no|[19.0,0.0,123.0,0...|[0.0,0.0,0.039390...|     10.0|                 1.0|            3.0|          0.0|          1.0|     17.0|          0.0|        6.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|    (3,[],[])|(1,[0],[1.0])|  (1,[],[])|(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(65,[10,12,16,35,...|(71,[2,5,16,18,22...|  0.0| [588.0,63.0]|[0.90322580645161...|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+-------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_dt.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : DT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.860340479193\n",
      "Test accuracy = 0.82357301705\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_dt = train_predictions_dt.select(\"prediction\", \"label\")\n",
    "train_accuracy_dt = evaluator.evaluate(predictionAndLabels_train_dt)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_dt))\n",
    "\n",
    "predictionAndLabels_test_dt = test_predictions_dt.select(\"prediction\", \"label\")\n",
    "test_accuracy_dt = evaluator.evaluate(predictionAndLabels_test_dt)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_Pipeline = Pipeline(stages=preprocessiong_Stages+[rf]) \n",
    "\n",
    "rf_Pipeline_model = rf_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_rf = rf_Pipeline_model.transform(trainingData)\n",
    "test_predictions_rf = rf_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|label|       rawPrediction|         probability|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "| 19|student|        single|  primary|     no|  103.0|     no|  no|cellular| 10|  jul|   104.0|     2.0| -1.0|     0.0| unknown|            yes|[19.0,103.0,104.0...|[0.0,0.0014468730...|     10.0|                 1.0|            2.0|          0.0|          1.0|     27.0|          0.0|        1.0|           0.0|                  1.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[2],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[27],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|          (1,[],[])|(65,[10,12,15,16,...|(71,[1,2,5,16,18,...|  0.0|[7.93229067786437...|[0.79322906778643...|       0.0|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no|cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|             no|[19.0,0.0,123.0,0...|[0.0,0.0,0.039390...|     10.0|                 1.0|            3.0|          0.0|          1.0|     17.0|          0.0|        6.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|    (3,[],[])|(1,[0],[1.0])|  (1,[],[])|(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(65,[10,12,16,35,...|(71,[2,5,16,18,22...|  0.0|[8.94321496297500...|[0.89432149629750...|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_rf.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.854035308953\n",
      "Test accuracy = 0.830985915493\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_rf = train_predictions_rf.select(\"prediction\", \"label\")\n",
    "train_accuracy_rf = evaluator.evaluate(predictionAndLabels_train_rf)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_rf))\n",
    "\n",
    "predictionAndLabels_test_rf = test_predictions_rf.select(\"prediction\", \"label\")\n",
    "test_accuracy_rf = evaluator.evaluate(predictionAndLabels_test_rf)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbt_Pipeline = Pipeline(stages=preprocessiong_Stages+[gbt]) \n",
    "\n",
    "gbt_Pipeline_model = gbt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_gbt = gbt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_gbt = gbt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|label|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+----------+\n",
      "| 19|student|        single|  primary|     no|  103.0|     no|  no|cellular| 10|  jul|   104.0|     2.0| -1.0|     0.0| unknown|            yes|[19.0,103.0,104.0...|[0.0,0.0014468730...|     10.0|                 1.0|            2.0|          0.0|          1.0|     27.0|          0.0|        1.0|           0.0|                  1.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[2],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[27],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|          (1,[],[])|(65,[10,12,15,16,...|(71,[1,2,5,16,18,...|  0.0|       0.0|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no|cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|             no|[19.0,0.0,123.0,0...|[0.0,0.0,0.039390...|     10.0|                 1.0|            3.0|          0.0|          1.0|     17.0|          0.0|        6.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|    (3,[],[])|(1,[0],[1.0])|  (1,[],[])|(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(65,[10,12,16,35,...|(71,[2,5,16,18,22...|  0.0|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_gbt.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : gbt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.866015132409\n",
      "Test accuracy = 0.824314306894\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_gbt = train_predictions_gbt.select(\"prediction\", \"label\")\n",
    "train_accuracy_gbt = evaluator.evaluate(predictionAndLabels_train_gbt)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_gbt))\n",
    "\n",
    "predictionAndLabels_test_gbt = test_predictions_gbt.select(\"prediction\", \"label\")\n",
    "test_accuracy_gbt = evaluator.evaluate(predictionAndLabels_test_gbt)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_gbt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
