{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SPARK_HOME and PYLIB env var and update PATH env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build __SparkConf__ object \n",
    "\n",
    "    Contains information about your application.  \n",
    "\n",
    "\n",
    "Create __SparkContext__ object \n",
    "    \n",
    "    Tells Spark how to access a cluster. \n",
    "    \n",
    "\n",
    "Create __SparkSession__ object\n",
    "\n",
    "    The entry point to programming Spark with the Dataset and DataFrame API.\n",
    "\n",
    "    Used to create DataFrame, register DataFrame as tables and execute SQL over tables etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"Universal Bank Data Set\").setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loading the dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "# from pyspark.sql.functions import isnan, when, count, col, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem Statement\n",
    "The dataset is from a bank, data related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, to access if the product (bank term deposit) would be (or not) subscribed. The data and attribute description are in the folder. \n",
    "\n",
    "\n",
    "#### Data Dictionary\n",
    " The dataset has the following attributes:\n",
    "\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                    \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "\n",
    "3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "\n",
    "5 - default: has credit in default? (binary: \"yes\",\"no\")\n",
    "\n",
    "#### 6 - balance: average yearly balance, in euros (numeric) \n",
    "\n",
    "7 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "\n",
    "10 - day: last contact day of the month (numeric)\n",
    "\n",
    "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "\n",
    "12 - duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "  \n",
    "15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "17 - Approved_no_yes - has the client subscribed to a __term deposit?__ (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the schema to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Schema\n",
    "bankDataSchema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"default\", StringType(), True),\n",
    "    StructField(\"balance\", DoubleType(), True),\n",
    "    StructField(\"housing\", StringType(), True),\n",
    "    StructField(\"loan\", StringType(), True),        \n",
    "    StructField(\"contact\", StringType(), True),\n",
    "    StructField(\"day\", IntegerType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"duration\", DoubleType(), True),\n",
    "    StructField(\"campaign\", DoubleType(), True),\n",
    "    StructField(\"pdays\", DoubleType(), True),\n",
    "    StructField(\"previous\", DoubleType(), True),\n",
    "    StructField(\"poutcome\", StringType(), True),\n",
    "    StructField(\"Approved_no_yes\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data and creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data and create a dataframe\n",
    "data = spark.read.format(\"csv\")\\\n",
    "       .option(\"header\", \"false\")\\\n",
    "       .option(\"inferSchema\", \"true\")\\\n",
    "       .load(\"hdfs:///user/jeevans/bankdata/\", schema = bankDataSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- campaign: double (nullable = true)\n",
      " |-- pdays: double (nullable = true)\n",
      " |-- previous: double (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- Approved_no_yes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to check the data type of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital_status', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'double'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'int'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'double'),\n",
       " ('campaign', 'double'),\n",
       " ('pdays', 'double'),\n",
       " ('previous', 'double'),\n",
       " ('poutcome', 'string'),\n",
       " ('Approved_no_yes', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of Columns and Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Columns = 17\n",
      "No. of Records = 4521\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Columns = {}\".format(len(data.columns)))\n",
    "\n",
    "print('No. of Records = {}'.format(data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at first 3 row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=30, job=u'unemployed', marital_status=u'married', education=u'primary', default=u'no', balance=1787.0, housing=u'no', loan=u'no', contact=u'cellular', day=19, month=u'oct', duration=79.0, campaign=1.0, pdays=-1.0, previous=0.0, poutcome=u'unknown', Approved_no_yes=u'no'),\n",
       " Row(age=33, job=u'services', marital_status=u'married', education=u'secondary', default=u'no', balance=4789.0, housing=u'yes', loan=u'yes', contact=u'cellular', day=11, month=u'may', duration=220.0, campaign=1.0, pdays=339.0, previous=4.0, poutcome=u'failure', Approved_no_yes=u'no'),\n",
       " Row(age=35, job=u'management', marital_status=u'single', education=u'tertiary', default=u'no', balance=1350.0, housing=u'yes', loan=u'no', contact=u'cellular', day=16, month=u'apr', duration=185.0, campaign=1.0, pdays=330.0, previous=1.0, poutcome=u'failure', Approved_no_yes=u'no')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|age|       job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "| 30|unemployed|       married|  primary|     no| 1787.0|     no|  no|cellular| 19|  oct|    79.0|     1.0| -1.0|     0.0| unknown|             no|\n",
      "| 33|  services|       married|secondary|     no| 4789.0|    yes| yes|cellular| 11|  may|   220.0|     1.0|339.0|     4.0| failure|             no|\n",
      "| 35|management|        single| tertiary|     no| 1350.0|    yes|  no|cellular| 16|  apr|   185.0|     1.0|330.0|     1.0| failure|             no|\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "|summary|               age|    job|marital_status|education|default|           balance|housing|loan| contact|               day|month|          duration|          campaign|             pdays|          previous|poutcome|Approved_no_yes|\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "|  count|              4521|   4521|          4521|     4521|   4521|              4521|   4521|4521|    4521|              4521| 4521|              4521|              4521|              4521|              4521|    4521|           4521|\n",
      "|   mean| 41.17009511170095|   null|          null|     null|   null|1422.6578190665782|   null|null|    null|15.915284229152842| null|263.96129174961294| 2.793629727936297|39.766644547666445|0.5425790754257908|    null|           null|\n",
      "| stddev|10.576210958711263|   null|          null|     null|   null|3009.6381424673395|   null|null|    null| 8.247667327229934| null|259.85663262468216|3.1098066601885823|100.12112444301656|1.6935623506071211|    null|           null|\n",
      "|    min|                19| admin.|      divorced|  primary|     no|           -3313.0|     no|  no|cellular|                 1|  apr|               4.0|               1.0|              -1.0|               0.0| failure|             no|\n",
      "|    max|                87|unknown|        single|  unknown|    yes|           71188.0|    yes| yes| unknown|                31|  sep|            3025.0|              50.0|             871.0|              25.0| unknown|            yes|\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show only fixed set of colums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----+------------------+------------------+\n",
      "|summary|               age|loan|           balance|             pdays|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "|  count|              4521|4521|              4521|              4521|\n",
      "|   mean| 41.17009511170095|null|1422.6578190665782|39.766644547666445|\n",
      "| stddev|10.576210958711263|null|3009.6381424673395|100.12112444301656|\n",
      "|    min|                19|  no|           -3313.0|              -1.0|\n",
      "|    max|                87| yes|           71188.0|             871.0|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().select('summary', 'age', 'loan', 'balance', 'pdays').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "\n",
    "    Balance has -ve values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.where(data.balance < 0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace negative balances with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('balance', when(data.balance > 0, data.balance).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values at each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|age|job|marital_status|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|  0|  0|             0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|              0|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and test sets (30% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list of categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_Var_Names = ['job', 'marital_status', 'education', 'default', 'housing', \n",
    "                 'loan', 'day', 'contact', 'month', 'poutcome', 'Approved_no_yes']\n",
    "\n",
    "num_Var_Names = ['age', 'duration', 'previous', 'pdays', 'campaign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use VectorAssembler to combine a given list of numcolumns into a single vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler_Num = VectorAssembler(inputCols=num_Var_Names, outputCol=\"num_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale all the numeric attributes using MinMaxScaler\n",
    "\n",
    "    MinMaxScaler transforms a dataset of Vector rows, rescaling each feature to a specific range (often [0, 1]). \n",
    "\n",
    "    MinMaxScaler computes summary statistics on a data set and produces a MinMaxScalerModel. The model can then transform each feature individually such that it is in the given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "min_Max_Scalar = MinMaxScaler(inputCol=\"num_features\", outputCol=\"scaled_num_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covert categorical to numeric : \n",
    "\n",
    "    OneHotEncoder, StringIndexer, VectorAssembler,  VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "indexers_Cat = [StringIndexer(inputCol=cat_Var_Name, outputCol=\"{0}_index\".format(cat_Var_Name)) for cat_Var_Name in cat_Var_Names ]\n",
    "encoders_Cat = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_vec\".format(indexer.getInputCol())) for indexer in indexers_Cat]\n",
    "assembler_Cat = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders_Cat], outputCol=\"cat_features\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"scaled_num_features\", \"cat_features\"], outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessiong_Stages = [assembler_Num]+[min_Max_Scalar]+indexers_Cat+encoders_Cat+[assembler_Cat]+[assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(maxIter=10, labelCol=\"balance\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr_Pipeline = Pipeline(stages=preprocessiong_Stages+[lr]) \n",
    "\n",
    "lr_Pipeline_model = lr_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [868.874044464,-441.108182646,522.687594496,-104.289169877,-497.336053763,515.008241408,2.89641699949,205.307369835,40.5057608004,92.3141144337,824.009277885,77.8209084445,632.989081613,23.1442099924,894.581526324,-107.089425044,360.247598293,477.839801578,-369.33013256,-180.35338757,-303.427839034,1208.51392942,-114.484803343,408.113940147,783.386976751,899.766534576,709.477855079,317.519297351,1033.5948376,69.7654398607,1059.35179227,713.739360509,675.513275397,881.834605104,1207.15950729,176.342058092,553.424348835,373.82871893,458.910801253,569.138820696,899.19730639,769.059600712,295.921796401,1000.99759171,606.222994592,551.271101529,219.896776202,1014.42335449,702.667435941,1122.97911173,-108.70090842,1485.31218723,179.804345479,575.673947405,-92.4701750924,-124.072427577,-2787.55193241,-3276.76242128,-2718.07233186,-2279.14673302,-1740.82029764,-2486.91196124,-2795.66734152,-3078.26970129,-916.496852529,-2358.37648362,-2549.49812436,25.4619280769,-19.3183900288,-62.044561505,13.9057816434]\n",
      "Intercept: 1475.80459216\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(lr_Pipeline_model.stages[-1].coefficients))\n",
    "print(\"Intercept: \" + str(lr_Pipeline_model.stages[-1].intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_lr = lr_Pipeline_model.transform(trainingData)\n",
    "test_predictions_lr = lr_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "|age|     job|marital_status|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|loan_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|     loan_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|        prediction|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "| 21|services|        single|secondary|     no|  361.0|     no|  no|telephone|  5|  jun|   329.0|     1.0| 95.0|     1.0|   other|             no|[21.0,329.0,1.0,9...|[0.02985074626865...|      4.0|                 1.0|            0.0|          0.0|          1.0|       0.0|      8.0|          2.0|        3.0|           2.0|                  0.0| (11,[4],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])| (30,[8],[1.0])|    (2,[],[])|(11,[3],[1.0])|(3,[2],[1.0])|      (1,[0],[1.0])|(66,[4,12,13,16,1...|(71,[0,1,2,3,9,17...|1626.3215349119878|\n",
      "| 21| student|        single|secondary|     no|    6.0|     no|  no|  unknown|  9|  may|   622.0|     1.0| -1.0|     0.0| unknown|             no|[21.0,622.0,0.0,-...|[0.02985074626865...|     10.0|                 1.0|            0.0|          0.0|          1.0|       0.0|     15.0|          1.0|        0.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])|(30,[15],[1.0])|(2,[1],[1.0])|(11,[0],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(66,[10,12,13,16,...|(71,[0,1,15,17,18...| 726.4347855504419|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_lr.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE  = 2974.83648786\n",
      "Test RMSE = 2729.75583955\n"
     ]
    }
   ],
   "source": [
    "# Find the error metric - RMSE\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"balance\", predictionCol=\"prediction\", metricName=\"rmse\" )\n",
    "\n",
    "train_rmse_lr = evaluator.evaluate(train_predictions_lr)\n",
    "print(\"Train RMSE  = \" + str(train_rmse_lr))\n",
    "\n",
    "test_rmse_lr = evaluator.evaluate(test_predictions_lr)\n",
    "print(\"Test RMSE = \" + str(test_rmse_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(labelCol=\"balance\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_Pipeline = Pipeline(stages=preprocessiong_Stages+[dt]) \n",
    "\n",
    "dt_Pipeline_model = dt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_dt = dt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_dt = dt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----------------+\n",
      "|age|     job|marital_status|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|loan_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|     loan_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|       prediction|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----------------+\n",
      "| 21|services|        single|secondary|     no|  361.0|     no|  no|telephone|  5|  jun|   329.0|     1.0| 95.0|     1.0|   other|             no|[21.0,329.0,1.0,9...|[0.02985074626865...|      4.0|                 1.0|            0.0|          0.0|          1.0|       0.0|      8.0|          2.0|        3.0|           2.0|                  0.0| (11,[4],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])| (30,[8],[1.0])|    (2,[],[])|(11,[3],[1.0])|(3,[2],[1.0])|      (1,[0],[1.0])|(66,[4,12,13,16,1...|(71,[0,1,2,3,9,17...|1117.564891846922|\n",
      "| 21| student|        single|secondary|     no|    6.0|     no|  no|  unknown|  9|  may|   622.0|     1.0| -1.0|     0.0| unknown|             no|[21.0,622.0,0.0,-...|[0.02985074626865...|     10.0|                 1.0|            0.0|          0.0|          1.0|       0.0|     15.0|          1.0|        0.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])|(30,[15],[1.0])|(2,[1],[1.0])|(11,[0],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(66,[10,12,13,16,...|(71,[0,1,15,17,18...|1117.564891846922|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_dt.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : DT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE  = 2679.17101032\n",
      "Test RMSE = 3631.36617782\n"
     ]
    }
   ],
   "source": [
    "train_rmse_dt = evaluator.evaluate(train_predictions_dt)\n",
    "print(\"Train RMSE  = \" + str(train_rmse_dt))\n",
    "\n",
    "test_rmse_dt = evaluator.evaluate(test_predictions_dt)\n",
    "print(\"Test RMSE = \" + str(test_rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(labelCol=\"balance\", featuresCol=\"features\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Pipeline = Pipeline(stages=preprocessiong_Stages+[rf]) \n",
    "\n",
    "rf_Pipeline_model = rf_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_rf = rf_Pipeline_model.transform(trainingData)\n",
    "test_predictions_rf = rf_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "|age|     job|marital_status|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|loan_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|     loan_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|        prediction|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "| 21|services|        single|secondary|     no|  361.0|     no|  no|telephone|  5|  jun|   329.0|     1.0| 95.0|     1.0|   other|             no|[21.0,329.0,1.0,9...|[0.02985074626865...|      4.0|                 1.0|            0.0|          0.0|          1.0|       0.0|      8.0|          2.0|        3.0|           2.0|                  0.0| (11,[4],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])| (30,[8],[1.0])|    (2,[],[])|(11,[3],[1.0])|(3,[2],[1.0])|      (1,[0],[1.0])|(66,[4,12,13,16,1...|(71,[0,1,2,3,9,17...|1473.5755806610805|\n",
      "| 21| student|        single|secondary|     no|    6.0|     no|  no|  unknown|  9|  may|   622.0|     1.0| -1.0|     0.0| unknown|             no|[21.0,622.0,0.0,-...|[0.02985074626865...|     10.0|                 1.0|            0.0|          0.0|          1.0|       0.0|     15.0|          1.0|        0.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])|(30,[15],[1.0])|(2,[1],[1.0])|(11,[0],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(66,[10,12,13,16,...|(71,[0,1,15,17,18...|1039.0046504565883|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_rf.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE  = 2672.8105754\n",
      "Test RMSE = 2740.71203683\n"
     ]
    }
   ],
   "source": [
    "train_rmse_rf = evaluator.evaluate(train_predictions_rf)\n",
    "print(\"Train RMSE  = \" + str(train_rmse_rf))\n",
    "\n",
    "test_rmse_rf = evaluator.evaluate(test_predictions_rf)\n",
    "print(\"Test RMSE = \" + str(test_rmse_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(labelCol=\"balance\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_Pipeline = Pipeline(stages=preprocessiong_Stages+[gbt]) \n",
    "\n",
    "gbt_Pipeline_model = gbt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_gbt = gbt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_gbt = gbt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "|age|     job|marital_status|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|loan_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|     loan_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|        prediction|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "| 21|services|        single|secondary|     no|  361.0|     no|  no|telephone|  5|  jun|   329.0|     1.0| 95.0|     1.0|   other|             no|[21.0,329.0,1.0,9...|[0.02985074626865...|      4.0|                 1.0|            0.0|          0.0|          1.0|       0.0|      8.0|          2.0|        3.0|           2.0|                  0.0| (11,[4],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])| (30,[8],[1.0])|    (2,[],[])|(11,[3],[1.0])|(3,[2],[1.0])|      (1,[0],[1.0])|(66,[4,12,13,16,1...|(71,[0,1,2,3,9,17...|1135.9308812542836|\n",
      "| 21| student|        single|secondary|     no|    6.0|     no|  no|  unknown|  9|  may|   622.0|     1.0| -1.0|     0.0| unknown|             no|[21.0,622.0,0.0,-...|[0.02985074626865...|     10.0|                 1.0|            0.0|          0.0|          1.0|       0.0|     15.0|          1.0|        0.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(1,[0],[1.0])|(30,[15],[1.0])|(2,[1],[1.0])|(11,[0],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(66,[10,12,13,16,...|(71,[0,1,15,17,18...|1070.5757041036522|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+----------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+-------------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_gbt.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : gbt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE  = 2393.73615068\n",
      "Test RMSE = 3677.13057598\n"
     ]
    }
   ],
   "source": [
    "train_rmse_gbt = evaluator.evaluate(train_predictions_gbt)\n",
    "\n",
    "print(\"Train RMSE  = \" + str(train_rmse_gbt))\n",
    "\n",
    "test_rmse_gbt = evaluator.evaluate(test_predictions_gbt)\n",
    "\n",
    "print(\"Test RMSE = \" + str(test_rmse_gbt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
