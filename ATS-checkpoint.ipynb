{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "bad escape \\p at position 257",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-813cd0367c18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#spacy.load('en_core_web_sm')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# installed as package\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# path to model data directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;34m\"\"\"Load a model from an installed package.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\en_core_web_sm\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, **overrides)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath2str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(self, path, exclude, disable)\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[1;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"vocab\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[1;31m# Split to support file names like meta.json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    926\u001b[0m         ) and _fix_pretrained_vectors_name(self)\n\u001b[0;32m    927\u001b[0m         deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(\n\u001b[1;32m--> 928\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"vocab\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    929\u001b[0m         )\n\u001b[0;32m    930\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.from_disk\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.from_bytes\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(str, flags, pattern)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[1;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[1;32m--> 426\u001b[1;33m                            not nested and not items))\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    534\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m                     \u001b[0mcode1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_escape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthis\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m'-&~|'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_class_escape\u001b[1;34m(source, escape)\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mASCIILETTERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad escape %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mescape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mLITERAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\p at position 257"
     ]
    }
   ],
   "source": [
    "#Resume Phrase Matcher code\n",
    "\n",
    "\n",
    "#importing all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import PyPDF2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import en_core_web_sm\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')  \n",
    "\n",
    "#spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read resumes from the folder one by one\n",
    "mypath='/Users/babysupriyavalikala/Documents/CandidateResume/' #enter your path here where you saved the resumes\n",
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "\n",
    "\n",
    "#For mypath, the documents were in pdf format.\n",
    "\n",
    "#The onlyfiles line checks whether the address of the folder is valid \n",
    "#and does contain the documents and if yes, then it iterated over the pdf \n",
    "#documents one by one.\n",
    "#every f is a resume(file) here \n",
    "#braces indicarte list here --and condition to store in list is given \n",
    "#if File is in path and file is a resume(pdf)--it gets stored in the list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfextract(file):\n",
    "    fileReader = PyPDF2.PdfFileReader(open(file,'rb'))  #it reads three files one by one\n",
    "    countpage = fileReader.getNumPages()                #number of pages in a file\n",
    "    count = 0\n",
    "    text = []\n",
    "    while count < countpage:    \n",
    "        pageObj = fileReader.getPage(count)          #iterating every page content here   \n",
    "        count +=1                                  \n",
    "        t = pageObj.extractText()                   #extracting text from each page--and adding to text list \n",
    "        \n",
    "        print (t)\n",
    "        text.append(t)\n",
    "    return text                 #text is a LIST - it contains the text of first resume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that does phrase matching and builds a candidate profile\n",
    "\n",
    "#it does segregation\n",
    "def create_profile(file):\n",
    "    text = pdfextract(file) \n",
    "    text = str(text)              #converting the string to text\n",
    "    text = text.replace(\"\\\\n\", \"\")#replace \\\\n with NULL\n",
    "     \n",
    "    text = text.lower()           #text to lower case\n",
    "    #below is the csv where we have all the keywords, you can customize your own\n",
    "    a=csv.reader('template.csv',delimiter=',')\n",
    "    keyword_dict =a\n",
    "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    #list   dropna--drop column if the value is NA(not arithmetic)\n",
    "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffStatistics', 'Machine Learning', 'Deep Learning', 'R Language', 'Python Language', 'NLP', 'Data Engineering']\n",
      "['statistical models', 'linear regression', 'neural network', 'r', 'python', 'nlp', 'aws']\n",
      "['statistical modeling', 'logistic regression', 'keras', 'ggplot', 'flask', 'natural language processing', 'ec2']\n",
      "['probability', 'K means', 'theano', 'shiny', 'django', 'topic modeling', 'amazon redshift']\n",
      "['normal distribution', 'random forest ', 'face detection ', 'cran', 'pandas', 'lda', 's3']\n",
      "['poisson distribution', 'xgboost', 'neural networks', 'dplyr', 'numpy', 'named entity recognition', 'docker']\n",
      "['survival models', 'svm', 'convolutional neural network (cnn)', 'tidyr', 'scikitlearn', 'pos tagging', 'kubernetes']\n",
      "['hypothesis testing', 'naïve bayes', 'recurrent neural network(RNN)', 'lubridate', 'sklearn ', 'word2vec', 'scala']\n",
      "['bayesian inference', 'pca', 'object detection', 'knitr', 'matplotlib', 'word embedding', 'teradata ']\n",
      "['factor analysis', 'decision trees', 'yolo', '', 'scipy', 'lsi', 'google big query']\n",
      "['forecasting', 'svd', 'gpu', '', 'bokeh', 'spacy', 'aws lambda']\n",
      "['markov chain', 'ensemble models', 'cuda', '', 'statsmodel', 'gensim', 'aws emr']\n",
      "['monte carlo', 'boltzman machine', 'tensorflow', '', '', 'nltk', 'hive']\n",
      "['', '', 'lstm', '', '', 'nmf', 'hadoop']\n",
      "['', '', 'gan', '', '', 'doc2vec', 'sql']\n",
      "['', '', 'opencv', '', '', 'cbow', '']\n",
      "['', '', '', '', '', 'bag of words', '']\n",
      "['', '', '', '', '', 'skip gram', '']\n",
      "['', '', '', '', '', 'bert', '']\n",
      "['', '', '', '', '', 'sentiment analysis', '']\n",
      "['', '', '', '', '', 'chat bot', '']\n"
     ]
    }
   ],
   "source": [
    "#for row in a:\n",
    "#    print (row)\n",
    "    \n",
    "    \n",
    "with open('template.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Statistics     Machine Learning  \\\n",
      "0     statistical models    linear regression   \n",
      "1   statistical modeling  logistic regression   \n",
      "2            probability              K means   \n",
      "3    normal distribution       random forest    \n",
      "4   poisson distribution              xgboost   \n",
      "5        survival models                  svm   \n",
      "6     hypothesis testing          naïve bayes   \n",
      "7     bayesian inference                  pca   \n",
      "8        factor analysis       decision trees   \n",
      "9            forecasting                  svd   \n",
      "10          markov chain      ensemble models   \n",
      "11           monte carlo     boltzman machine   \n",
      "12                   NaN                  NaN   \n",
      "13                   NaN                  NaN   \n",
      "14                   NaN                  NaN   \n",
      "15                   NaN                  NaN   \n",
      "16                   NaN                  NaN   \n",
      "17                   NaN                  NaN   \n",
      "18                   NaN                  NaN   \n",
      "19                   NaN                  NaN   \n",
      "\n",
      "                         Deep Learning R Language Python Language  \\\n",
      "0                       neural network          r          python   \n",
      "1                                keras     ggplot           flask   \n",
      "2                               theano      shiny          django   \n",
      "3                      face detection        cran          pandas   \n",
      "4                      neural networks      dplyr           numpy   \n",
      "5   convolutional neural network (cnn)      tidyr     scikitlearn   \n",
      "6        recurrent neural network(RNN)  lubridate        sklearn    \n",
      "7                     object detection      knitr      matplotlib   \n",
      "8                                 yolo        NaN           scipy   \n",
      "9                                  gpu        NaN           bokeh   \n",
      "10                                cuda        NaN      statsmodel   \n",
      "11                          tensorflow        NaN             NaN   \n",
      "12                                lstm        NaN             NaN   \n",
      "13                                 gan        NaN             NaN   \n",
      "14                              opencv        NaN             NaN   \n",
      "15                                 NaN        NaN             NaN   \n",
      "16                                 NaN        NaN             NaN   \n",
      "17                                 NaN        NaN             NaN   \n",
      "18                                 NaN        NaN             NaN   \n",
      "19                                 NaN        NaN             NaN   \n",
      "\n",
      "                            NLP  Data Engineering  \n",
      "0                           nlp               aws  \n",
      "1   natural language processing               ec2  \n",
      "2                topic modeling   amazon redshift  \n",
      "3                           lda                s3  \n",
      "4      named entity recognition            docker  \n",
      "5                   pos tagging        kubernetes  \n",
      "6                      word2vec             scala  \n",
      "7                word embedding         teradata   \n",
      "8                           lsi  google big query  \n",
      "9                         spacy        aws lambda  \n",
      "10                       gensim           aws emr  \n",
      "11                         nltk              hive  \n",
      "12                          nmf            hadoop  \n",
      "13                      doc2vec               sql  \n",
      "14                         cbow               NaN  \n",
      "15                 bag of words               NaN  \n",
      "16                    skip gram               NaN  \n",
      "17                         bert               NaN  \n",
      "18           sentiment analysis               NaN  \n",
      "19                     chat bot               NaN  \n"
     ]
    }
   ],
   "source": [
    "keyword_dict=pd.read_csv('template.csv')\n",
    "print(keyword_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that does phrase matching and builds a candidate profile\n",
    "def create_profile(file):\n",
    "    text = pdfextract(file) \n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    #below is the csv where we have all the keywords, you can customize your own\n",
    "    keyword_dict = pd.read_csv('D:/NLP_Resume/resume/template_new.csv')\n",
    "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
    "\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Stats', None, *stats_words)\n",
    "    matcher.add('NLP', None, *NLP_words)\n",
    "    matcher.add('ML', None, *ML_words)\n",
    "    matcher.add('DL', None, *DL_words)\n",
    "    matcher.add('R', None, *R_words)\n",
    "    matcher.add('Python', None, *python_words)\n",
    "    matcher.add('DE', None, *Data_Engineering_words)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []  \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "        span = doc[start : end]  # get the matched slice of the doc\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function that does phrase matching and builds a candidate profile\n",
    "def create_profile(file):\n",
    "    text = pdfextract(file) \n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    #below is the csv where we have all the keywords, you can customize your own\n",
    "    keyword_dict = pd.read_csv('D:/NLP_Resume/resume/template_new.csv')\n",
    "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
    "\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Stats', None, *stats_words)\n",
    "    matcher.add('NLP', None, *NLP_words)\n",
    "    matcher.add('ML', None, *ML_words)\n",
    "    matcher.add('DL', None, *DL_words)\n",
    "    matcher.add('R', None, *R_words)\n",
    "    matcher.add('Python', None, *python_words)\n",
    "    matcher.add('DE', None, *Data_Engineering_words)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []  \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "        span = doc[start : end]  # get the matched slice of the doc\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    \n",
    "    ## convertimg string of keywords to dataframe\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    \n",
    "    base = os.path.basename(file)\n",
    "    filename = os.path.splitext(base)[0]\n",
    "       \n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "\n",
    "    return(dataf)\n",
    "        \n",
    "#function ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "PdfReadError",
     "evalue": "Could not read malformed PDF file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-185bdc851e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monlyfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monlyfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfinal_database\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-fda2eb67e753>\u001b[0m in \u001b[0;36mcreate_profile\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#function that does phrase matching and builds a candidate profile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-24bc6736cf4f>\u001b[0m in \u001b[0;36mpdfextract\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpdfextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfileReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#it reads three files one by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcountpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m#number of pages in a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, strict, warndest, overwriteWarnings)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlast1K\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EOF marker not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNextEndLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  line:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36mreadNextEndLine\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1935\u001b[0m             \u001b[0;31m# Prevent infinite loops in malformed PDFs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1937\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not read malformed PDF file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1938\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  x:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%x\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPdfReadError\u001b[0m: Could not read malformed PDF file"
     ]
    }
   ],
   "source": [
    "#code to execute/call the above functions\n",
    "\n",
    "final_database=pd.DataFrame()\n",
    "i = 0 \n",
    "while i < len(onlyfiles):\n",
    "    file = onlyfiles[i]\n",
    "    dat = create_profile(file)\n",
    "    final_database = final_database.append(dat)\n",
    "    i +=1\n",
    "    print(final_database)\n",
    "\n",
    "    #code to count words under each category and visulaize it through Matplotlib\n",
    "\n",
    "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "final_database2.reset_index(inplace = True)\n",
    "final_database2.fillna(0,inplace=True)\n",
    "new_data = final_database2.iloc[:,1:]\n",
    "new_data.index = final_database2['Candidate Name']\n",
    "#execute the below line if you want to see the candidate profile in a csv format\n",
    "#sample2=new_data.to_csv('sample.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(25,7), stacked=True)\n",
    "labels = []\n",
    "for j in new_data.columns:\n",
    "    for i in new_data.index:\n",
    "        label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "        labels.append(label)\n",
    "patches = ax.patches\n",
    "for label, rect in zip(labels, patches):\n",
    "    width = rect.get_width()\n",
    "    if width > 0:\n",
    "        x = rect.get_x()\n",
    "        y = rect.get_y()\n",
    "        height = rect.get_height()\n",
    "        ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
