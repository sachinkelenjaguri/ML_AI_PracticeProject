{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP vs CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras model module\n",
    "\n",
    "    Import the Sequential model type from Keras. This is an interface to build a linear stack of neural network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras core layers\n",
    "    \n",
    "    Import the \"core\" layers from Keras. These are the layers that are used in almost any neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras CNN layers\n",
    "\n",
    "     Import the CNN layers from Keras. These are the convolutional layers that will help us efficiently train on image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import convolutional, pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load image data from MNIST.\n",
    "\n",
    "    MNIST database of handwritten digits\n",
    "\n",
    "    Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    " \n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns:\n",
    "\n",
    "    2 tuples:\n",
    "            x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
    "            y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,).\n",
    "\n",
    "Arguments:\n",
    "\n",
    "    path: if you do not have the index file locally (at '~/.keras/datasets/' + path), it will be downloaded to this location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the shape of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for MNIST Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MNIST Data for MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our data type to float32 and normalize our data values to the range [0, 1]\n",
    "\n",
    "Note: Max value X_train/X_test can take is 255, so it is divided by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the shape of our class label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have 10 different classes, one for each digit, but it looks like we only have a 1-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print (y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Convert 1-dimensional class arrays to 10-dimensional class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take another look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same number of samples, but flatten the 28, 28 to 28*28 (784)\n",
    "\n",
    "X_train_mlp = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "\n",
    "X_test_mlp = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train_mlp.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 538,890\n",
      "Trainable params: 537,354\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0679 - val_acc: 0.9824\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0679 - val_acc: 0.9825\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0679 - val_acc: 0.9825\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0679 - val_acc: 0.9826\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0679 - val_acc: 0.9826\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0680 - val_acc: 0.9826\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0680 - val_acc: 0.9826\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9826\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0680 - val_acc: 0.9827\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0681 - val_acc: 0.9827\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0681 - val_acc: 0.9827\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_mlp, Y_train, validation_split = 0.2,\n",
    "                    batch_size = 48000, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCzMzy+SwMDOzTP8fPfHJUMDNzh4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21de1927518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJlZLpxgzMwsF/8/U8f0pv2K2oIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21c7036c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test score - 0.05498260830409308\n",
      "[INFO] test accuracy - 0.9862\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_mlp, Y_test, verbose=0)\n",
    "\n",
    "print(\"[INFO] test score - {}\".format(scores[0]))\n",
    "\n",
    "print(\"[INFO] test accuracy - {}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/convolutions.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/convolution_matrix.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Feature Map Dimensions after Convolving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/conv_output_feature_map_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        W - Width of the input feature map\n",
    "        \n",
    "        K - Width of the Kernel / Filter\n",
    "        \n",
    "        P - Padding Layer dimension\n",
    "        \n",
    "        S - Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Padding in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  In Keras we have two types of Padding:\n",
    "    \n",
    "      (i) Valid Padding : Any layer that does not fully intersect with the filter is ignored (NO PADDING!)\n",
    "        \n",
    "      (ii) Same Padding : Adds Zero Padding such that the output feature map has similar dimensions to the input                      feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/zero_padding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/same_padding.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for MNIST Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess input data for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape input data\n",
    "\n",
    "    When using the tensorflow backend, you must explicitly declare a dimension for the depth of the input image. \n",
    "    E.g. a full-color image with all 3 RGB channels will have a depth of 3.\n",
    "\n",
    "    Our MNIST images only have a depth of 1, but we must explicitly declare that. \n",
    "\n",
    "    In other words, we want to transform our dataset from having shape (n, width, height) to (n, width, height, channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " print X_train's dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_train_cnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the input layer\n",
    "\n",
    "CNN input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), activation='relu', input_shape=(28,28,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### 2D convolution layer (e.g. spatial convolution over images).\n",
    "\n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n",
    "\n",
    "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(28, 28, 1) for 28x28 gray pictures in data_format=\"channels_last\".\n",
    "\n",
    "First parameters correspond to the number of convolution filters \n",
    "\n",
    "Next 2 parameters correspond to kernal size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add more layers to our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/max_pooling.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides = (1,1), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides = (1,1), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout\n",
    "\n",
    "    This is a method for regularizing our model in order to prevent overfitting. \n",
    "\n",
    "MaxPooling2D \n",
    "\n",
    "    Is a way to reduce the number of parameters in our model by sliding a 2x2 pooling filter across the previous layer and taking the max of the 4 values in the 2x2 filter.\n",
    "\n",
    "So far, for model parameters, we've added two Convolution layers. To complete our model architecture, let's add a fully connected layer and then the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Dense layers, the first parameter is the output size of the layer. Keras automatically handles the connections between layers.\n",
    "\n",
    "Note that the final layer has an output size of 10, corresponding to the 10 classes of digits.\n",
    "\n",
    "Also note that the weights from the Convolution layers must be flattened (made 1-dimensional) before passing them to the fully connected Dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model by providing the loss function and the optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_adam = Adam(lr = 0.01, decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(loss = 'categorical_crossentropy', optimizer = custom_adam, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 32)          18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 62,218\n",
      "Trainable params: 61,898\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.5375 - acc: 0.8534 - val_loss: 0.2644 - val_acc: 0.9649\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.2056 - acc: 0.9403 - val_loss: 0.1300 - val_acc: 0.9763\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.1533 - acc: 0.9572 - val_loss: 0.0899 - val_acc: 0.9802\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.1207 - acc: 0.9662 - val_loss: 0.0593 - val_acc: 0.9848\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.1057 - acc: 0.9696 - val_loss: 0.0522 - val_acc: 0.9861\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0965 - acc: 0.9727 - val_loss: 0.0442 - val_acc: 0.9872\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0904 - acc: 0.9744 - val_loss: 0.0429 - val_acc: 0.9881\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0858 - acc: 0.9760 - val_loss: 0.0387 - val_acc: 0.9895\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0815 - acc: 0.9762 - val_loss: 0.0361 - val_acc: 0.9903\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.0791 - acc: 0.9776 - val_loss: 0.0358 - val_acc: 0.9903\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.0735 - acc: 0.9795 - val_loss: 0.0371 - val_acc: 0.9892\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0730 - acc: 0.9793 - val_loss: 0.0349 - val_acc: 0.9893\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0687 - acc: 0.9799 - val_loss: 0.0326 - val_acc: 0.9901\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0661 - acc: 0.9813 - val_loss: 0.0333 - val_acc: 0.9904\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0660 - acc: 0.9808 - val_loss: 0.0333 - val_acc: 0.9902\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0623 - acc: 0.9818 - val_loss: 0.0313 - val_acc: 0.9917\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0609 - acc: 0.9826 - val_loss: 0.0299 - val_acc: 0.9920\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0611 - acc: 0.9824 - val_loss: 0.0292 - val_acc: 0.9915\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0583 - acc: 0.9832 - val_loss: 0.0316 - val_acc: 0.9906\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0566 - acc: 0.9834 - val_loss: 0.0305 - val_acc: 0.9917\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.0578 - acc: 0.9828 - val_loss: 0.0306 - val_acc: 0.9919\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0592 - acc: 0.9828 - val_loss: 0.0290 - val_acc: 0.9917\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0545 - acc: 0.9849 - val_loss: 0.0292 - val_acc: 0.9922\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0565 - acc: 0.9842 - val_loss: 0.0289 - val_acc: 0.9922\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0530 - acc: 0.9848 - val_loss: 0.0296 - val_acc: 0.9921\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0536 - acc: 0.9845 - val_loss: 0.0297 - val_acc: 0.9919\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0525 - acc: 0.9846 - val_loss: 0.0288 - val_acc: 0.9923\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0504 - acc: 0.9853 - val_loss: 0.0280 - val_acc: 0.9928\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0505 - acc: 0.9852 - val_loss: 0.0289 - val_acc: 0.9918\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0507 - acc: 0.9857 - val_loss: 0.0284 - val_acc: 0.9920\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0491 - acc: 0.9853 - val_loss: 0.0276 - val_acc: 0.9924\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0494 - acc: 0.9853 - val_loss: 0.0272 - val_acc: 0.9929\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0496 - acc: 0.9857 - val_loss: 0.0269 - val_acc: 0.9932\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0480 - acc: 0.9864 - val_loss: 0.0276 - val_acc: 0.9921\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.0473 - acc: 0.9858 - val_loss: 0.0278 - val_acc: 0.9925\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0479 - acc: 0.9856 - val_loss: 0.0276 - val_acc: 0.9917\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0453 - acc: 0.9867 - val_loss: 0.0270 - val_acc: 0.9922\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0456 - acc: 0.9864 - val_loss: 0.0273 - val_acc: 0.9927\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0450 - acc: 0.9871 - val_loss: 0.0267 - val_acc: 0.9926\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0427 - acc: 0.9874 - val_loss: 0.0262 - val_acc: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c0fc242b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train_cnn, Y_train, batch_size = 4096, epochs = 40, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 109us/step\n",
      "[0.024113903012243098, 0.9932]\n"
     ]
    }
   ],
   "source": [
    "score = cnn_model.evaluate(X_test_cnn, Y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = cnn_model.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.13929830e-08 6.25930852e-06 1.10057726e-05 ... 9.99974966e-01\n",
      "  8.13344414e-09 2.03555055e-06]\n",
      " [2.16912781e-06 3.96288033e-06 9.99975204e-01 ... 1.10124790e-06\n",
      "  1.78475591e-06 6.75249012e-09]\n",
      " [2.68728786e-06 9.99902368e-01 1.92760263e-06 ... 7.17751973e-05\n",
      "  1.97013856e-06 8.63880416e-07]\n",
      " ...\n",
      " [4.68069361e-09 4.22520543e-08 1.17684511e-08 ... 1.16968195e-08\n",
      "  1.09242876e-07 1.97928512e-06]\n",
      " [2.65744063e-07 1.14192185e-08 1.02199152e-07 ... 1.27762655e-06\n",
      "  4.16286730e-06 1.66358841e-05]\n",
      " [1.95710563e-05 4.40763870e-07 1.95179064e-06 ... 3.22001537e-10\n",
      "  2.99412568e-06 8.06175478e-07]]\n"
     ]
    }
   ],
   "source": [
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_class = cnn_model.predict_classes(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 977,    0,    1,    0,    0,    0,    0,    1,    1,    0],\n",
       "       [   0, 1134,    0,    0,    0,    0,    0,    1,    0,    0],\n",
       "       [   1,    0, 1024,    1,    0,    0,    1,    5,    0,    0],\n",
       "       [   0,    0,    2, 1006,    0,    2,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,  978,    0,    0,    0,    0,    4],\n",
       "       [   0,    0,    0,    4,    0,  886,    1,    1,    0,    0],\n",
       "       [   2,    3,    0,    0,    1,    4,  946,    0,    2,    0],\n",
       "       [   0,    3,    3,    0,    0,    1,    0, 1018,    0,    3],\n",
       "       [   0,    0,    3,    1,    0,    0,    1,    0,  966,    3],\n",
       "       [   0,    0,    0,    0,    4,    4,    0,    2,    2,  997]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "\n",
    "    https://keras.io/\n",
    "    https://elitedatascience.com\n",
    "    http://scikit-learn.org/stable/modules/classes.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
